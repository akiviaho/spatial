{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18.1.2023\n",
    "# A space for functions and snippets that are not quite dead and dusted\n",
    "# but appear redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 \n",
    "\n",
    "from  scripts.utils import get_sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_spotclean_dict = {}\n",
    "for sample_id in samples:\n",
    "    adata = adata_dict[sample_id]\n",
    "    spotclean_data = pd.read_csv('./results/after_spotclean/'+sample_id+'_counts_after_spotclean.csv')\n",
    "    spotclean_data.columns = spotclean_data.columns.str.replace('.','-',regex=True)\n",
    "    adata_spotclean = ad.AnnData(X=spotclean_data.T)\n",
    "\n",
    "    if (adata.obs_names == adata_spotclean.obs_names).all():\n",
    "        print(str(sample_id) + ' has matching spot order. Copying spatial information...')\n",
    "        adata_spotclean.obs = adata.obs\n",
    "        adata_spotclean.uns = adata.uns\n",
    "        adata_spotclean.obsm = adata.obsm\n",
    "        adata_spotclean_dict[sample_id] = adata_spotclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for doing post-spotclean clustering. The data should have less variation present\n",
    "\n",
    "# Change the spatial proximity weight (weight) & resolution\n",
    "# weight ~0.1-0.3\n",
    "# resolution ~0.3-1.0\n",
    "\n",
    "resolution = 0.8\n",
    "for sample_id in samples:\n",
    "    adata_spotclean = adata_spotclean_dict[sample_id]\n",
    "    \n",
    "    # Since spotclean data is already normalized, there is only need to look for spatial neighbors and \n",
    "    # do PCA + clustering\n",
    "    sq.gr.spatial_neighbors(adata_spotclean, n_rings=2, coord_type=\"grid\", n_neighs=6,transform='cosine')\n",
    "    sc.pp.pca(adata_spotclean, n_comps=15)\n",
    "    sc.pp.neighbors(adata_spotclean)\n",
    "\n",
    "    for weight in [0.1,0.15,0.2,0.25,0.3]:\n",
    "        dir_path = './plots/spotclean_spatial_weight_'+str(weight)+'_resolution_'+str(resolution)\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        adata_spotclean = joint_cluster(adata_spotclean,proximity_weight=weight,res=resolution)\n",
    "        try:\n",
    "            sq.pl.spatial_scatter(adata_spotclean,color=['joint_leiden_clusters'],size=1.2,figsize=(8,8),dpi=120)\n",
    "        except:\n",
    "            adata_spotclean.uns.pop('joint_leiden_clusters_colors')\n",
    "            sq.pl.spatial_scatter(adata_spotclean,color=['joint_leiden_clusters'],size=1.2,figsize=(8,8),dpi=120)\n",
    "        plt.savefig(dir_path+'/'+sample_id+'_clusters_proximity_weight_'+str(weight)+'_resolution_'+str(resolution)+'.png')\n",
    "        plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for doing saving clustering results of one chosen parameter combination. \n",
    "# The results is exported in a format compatible with Loupe browser\n",
    "# resolution: 0.8\n",
    "# weight_ 0.2\n",
    "resolution = 0.8\n",
    "weight = 0.2\n",
    "for sample_id in samples:\n",
    "    #sample_id = 'PC_7875OIK'\n",
    "    adata = adata_dict[sample_id]\n",
    "    adata = calculate_neighbors(adata)\n",
    "\n",
    "\n",
    "    dir_path = './clustering/'\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    adata = joint_cluster(adata,proximity_weight=weight,res=resolution)\n",
    "    try:\n",
    "        sq.pl.spatial_scatter(adata,color=['joint_leiden_clusters'],size=1.2,figsize=(8,8),dpi=120)\n",
    "        plt.savefig(dir_path+'/'+sample_id+'_section_space_clusters_proximity_weight_'+str(weight)+'_resolution_'+str(resolution)+'.png')\n",
    "        plt.close()\n",
    "    #    sc.pl.scatter(adata,color=['joint_leiden_clusters'],size=1.2,figsize=(8,8),dpi=120)\n",
    "    #    plt.savefig(dir_path+'/'+sample_id+'_UMAP_space_clusters_proximity_weight_'+str(weight)+'_resolution_'+str(resolution)+'.png')\n",
    "    except:\n",
    "        adata.uns.pop('joint_leiden_clusters_colors')\n",
    "        sq.pl.spatial_scatter(adata,color=['joint_leiden_clusters'],size=1.2,figsize=(8,8),dpi=120)\n",
    "        plt.savefig(dir_path+'/'+sample_id+'_section_space_clusters_proximity_weight_'+str(weight)+'_resolution_'+str(resolution)+'.png')\n",
    "        plt.close()\n",
    "    #    sc.pl.scatter(adata,color=['joint_leiden_clusters'],size=1.2,figsize=(8,8),dpi=120)\n",
    "    #    plt.savefig(dir_path+'/'+sample_id+'_UMAP_space_clusters_proximity_weight_'+str(weight)+'_resolution_'+str(resolution)+'.png')\n",
    "    df_to_save = pd.DataFrame({'Barcode':adata.obs.index,'Joint Leiden': ['Cluster '+ cl for cl in adata.obs.joint_leiden_clusters]})\n",
    "    df_to_save.to_csv(dir_path+'/'+sample_id+'_clusters_proximity_weight_'+str(weight)+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert sample ids to barcodes and another column\n",
    "# Normalize samples according to scanpy standard pipeline\n",
    "for k in adata_dict.keys():\n",
    "    print(k)\n",
    "    adata_dict[k].obs['sample_id'] = k\n",
    "    adata_dict[k].obs_names = k + '_' + adata_dict[k].obs_names\n",
    "    sc.pp.filter_genes(adata_dict[k],min_cells=50)\n",
    "    sc.pp.filter_cells(adata_dict[k],min_genes=500)\n",
    "    sc.pp.normalize_total(adata_dict[k], target_sum=1e4)\n",
    "    sc.pp.log1p(adata_dict[k])\n",
    "    sc.pp.highly_variable_genes(adata_dict[k], min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "# Aggregate data to a single adata object\n",
    "adata_concat = sc.concat(adata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_neighbors(adata):\n",
    "    # normalize and calculate leiden clustering\n",
    "    sq.gr.spatial_neighbors(adata, n_rings=2, coord_type=\"grid\", n_neighs=6,transform='cosine')\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    sc.pp.pca(adata, n_comps=15)\n",
    "    sc.pp.neighbors(adata, random_state=42)\n",
    "    return adata\n",
    "\n",
    "def joint_cluster(adata,proximity_weight=0.0,res=1):\n",
    "    # Define the joint adjacency weighting\n",
    "    joint_adj = adata.obsp['spatial_connectivities']*proximity_weight + adata.obsp['connectivities']\n",
    "    sc.tl.leiden(adata,adjacency=joint_adj,key_added='joint_leiden_clusters',resolution=res,random_state=42)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spatial graph structures from individual Visium experiments just to be sure\n",
    "for s in samples:\n",
    "    adata_scan = adata_scanorama[adata_scanorama.obs['sample_id']==s]\n",
    "    if (adata_scan.obs_names == normalized_adata[s].obs_names).all():\n",
    "        sq.gr.spatial_neighbors(normalized_adata[s], n_rings=2, coord_type=\"grid\", n_neighs=6,transform='cosine')\n",
    "\n",
    "# Insert these results into the scanorama adata structure for later use\n",
    "adata = ad.concat(normalized_adata,pairwise=True)\n",
    "adata = adata[adata.obs.sort_index().index]\n",
    "if (adata.obs_names == adata_scanorama.obs_names).all():\n",
    "    adata_scanorama.obsp['spatial_connectivities'] = adata.obsp['spatial_connectivities'].copy()\n",
    "    adata_scanorama.obsp['spatial_distances'] = adata.obsp['spatial_distances'].copy()\n",
    "del adata\n",
    "\n",
    "# adata_scanorama should now have connectivities and distances for both scanorama integrated expression and spatial data\n",
    "adata_scanorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a scanorama-based cluster on a spatial section\n",
    "sample = 'BPH_651'\n",
    "cl_nmbr = [cluster]\n",
    "\n",
    "adata_vis = normalized_adata[sample].copy()\n",
    "adata_vis.obs = pd.merge(adata_vis.obs,adata_scanorama.obs['leiden'],left_index=True,right_index=True)\n",
    "adata_vis.obs['visualization'] = adata_vis.obs['leiden'].cat.set_categories(cl_nmbr)\n",
    "sq.pl.spatial_scatter(adata_vis,color=['visualization'],size=1.2,figsize=(6,6),dpi=120,legend_loc='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = adata.obs[['broad_celltypes','dataset']]\n",
    "meta['count'] = 1\n",
    "\n",
    "grouped_meta = meta.groupby(['dataset','broad_celltypes'],axis=0).sum()\n",
    "grouped_meta.reset_index(inplace=True)\n",
    "grouped_meta = grouped_meta.pivot(index='dataset',columns='broad_celltypes',values='count')\n",
    "grouped_meta = grouped_meta.loc[['dong_2020','chen_2021','song_2022','hirz_2023']]\n",
    "#grouped_meta.set_index('dataset',inplace=True)\n",
    "#grouped_meta\n",
    "grouped_meta.plot.bar(stacked=True,grid=False,yticks=(0,2e4,4e4,14e4),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
