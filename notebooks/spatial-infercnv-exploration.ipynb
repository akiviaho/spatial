{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak431480/.conda/envs/infercnvpy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/lustre/scratch/kiviaho/prostate_spatial')\n",
    "\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import infercnvpy as cnv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from scripts.utils import load_from_pickle, save_to_pickle, get_sample_ids_reorder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "chr_order = ['chr'+str(i) for i in np.arange(1,23)]\n",
    "\n",
    "def sort_chromosomes(vars,chromsomes = chr_order):\n",
    "    # Vars is a pandas dataframe with chromosomal annotation\n",
    "    # This function drops redundant genes and sorts the df by chromoal position\n",
    "\n",
    "    # Drop redundant from variables\n",
    "    vars = vars.dropna()\n",
    "    vars = vars[~((vars['chromosome'] == 'chrM')|(vars['chromosome'] == 'chrX') | (vars['chromosome'] == 'chrY'))]\n",
    "\n",
    "    # Sort variable to genomic pos\n",
    "    vars['chromosome'] = vars['chromosome'].astype('category').cat.set_categories(chromsomes)\n",
    "    vars = vars.sort_values(['chromosome','start'])\n",
    "\n",
    "    return(vars)\n",
    "\n",
    "def add_chromosome_bin_annotation(chr_variable_data, chr_list= chr_order, chromosome_bin_size=5e6):\n",
    "\n",
    "    annotated_chr_var = pd.DataFrame(columns=chr_variable_data.columns)\n",
    "    # Loop through each chromosme individually\n",
    "    for chr_name in chr_list:\n",
    "        # Subset the variables of a specific chromosome\n",
    "        var_df = chr_variable_data[chr_variable_data['chromosome'] == chr_name].copy()\n",
    "\n",
    "        # Loop through the genomic coordinates\n",
    "        prev_coord = None\n",
    "        prev_category = None\n",
    "\n",
    "        for i, coord in enumerate(var_df['start']):\n",
    "            if prev_coord is None:\n",
    "                # First coordinate, create a new category\n",
    "                var_df.at[var_df.index[i], 'chromosome_bin'] = chr_name+'.1'\n",
    "                prev_coord = coord\n",
    "                prev_category = chr_name+'.1'\n",
    "            elif coord - prev_coord <= chromosome_bin_size:\n",
    "                # Within 5 million, assign to same category as previous\n",
    "                var_df.at[var_df.index[i], 'chromosome_bin'] = prev_category\n",
    "            else:\n",
    "                # Outside 5 million, create a new category\n",
    "                new_category = f'{chr_name}.{int(prev_category.split(\".\")[-1])+1}'\n",
    "                var_df.at[var_df.index[i], 'chromosome_bin'] = new_category\n",
    "                prev_coord = var_df.at[var_df.index[i], 'end'] # Reel to the end of the gene and begin from there\n",
    "                prev_category = new_category\n",
    "        \n",
    "        # Concatenate the finished dataframe\n",
    "        annotated_chr_var = pd.concat([annotated_chr_var,var_df],axis = 0)\n",
    "    \n",
    "    return(annotated_chr_var)\n",
    "\n",
    "def threshold_matrix(matrix, lower_thr, upper_thr, lower_thr2, upper_thr2):\n",
    "\n",
    "    # Between the lowest and the second lowest threshold\n",
    "    below_thr2 = np.where((matrix > lower_thr) & (matrix < lower_thr2), -1, 0)\n",
    "\n",
    "    # Between the highest and the second highest threshold\n",
    "    above_thr2 = np.where((matrix < upper_thr) & (matrix > upper_thr2), 1, 0)\n",
    "\n",
    "    # Below the lowest threshold\n",
    "    below_thr = np.where(matrix < lower_thr, -2, 0)\n",
    "\n",
    "    # Above the highest threshold\n",
    "    above_thr = np.where(matrix > upper_thr, 2, 0)\n",
    "    result = below_thr + above_thr + below_thr2 + above_thr2\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnning infercnvpy (done already in a script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL OF THIS HAS BEEN DONE IN 'infercnvpy_on_visium.py'\n",
    "\n",
    "adata = load_from_pickle('./data/slides_with_cell_mapping_based_regions.pickle')\n",
    "samples = get_sample_ids()\n",
    "\n",
    "adata_concat = ad.concat(adata)\n",
    "\n",
    "# Extract the string before '-' or '_' in each entry\n",
    "adata_concat.obs['phenotype'] = [entry.split('-')[0].split('_')[0] for entry in adata_concat.obs['sample_id']]\n",
    "\n",
    "## Get the chromosomal coordinates\n",
    "cnv.io.genomic_position_from_gtf('./gencode.v43.annotation.gtf', adata_concat)\n",
    "\n",
    "\n",
    "# Filter the chromosomal coordinates\n",
    "adata_concat = adata_concat[:,sort_chromosomes(adata_concat.var).index].copy()\n",
    "\n",
    "# Save the coordinates\n",
    "vars = adata_concat.var.copy()\n",
    "vars.to_csv('genomic_positions_infercnvpy_formatted.csv')\n",
    "\n",
    "## create an anndata object of BPH luminal epithelial cells that will be used as ref.\n",
    "\n",
    "ref_cat = {'BPH_688':['5','6'],\n",
    "            'BPH_665':['2'],\n",
    "            'BPH_651':['1']}\n",
    "\n",
    "subset_data = []\n",
    "\n",
    "for idx, row in adata_concat.obs.iterrows():\n",
    "    sample_id = row['sample_id']\n",
    "    cluster = row['joint_leiden_clusters']\n",
    "    if sample_id in ref_cat and cluster in ref_cat[sample_id]:\n",
    "        subset_data.append(row)\n",
    "\n",
    "df_subset = pd.DataFrame(subset_data)\n",
    "ref_subset = adata_concat[df_subset.index]\n",
    "\n",
    "infercnv_dict = {}\n",
    "n_samples = len(samples)\n",
    "count = 1\n",
    "for sample in samples:\n",
    "    if 'BPH' not in sample:\n",
    "\n",
    "        adata_subset = adata_concat[adata_concat.obs['sample_id']==sample]\n",
    "\n",
    "        adata_subset = ad.concat([adata_subset,ref_subset],join='outer')\n",
    "\n",
    "        if (adata_subset.var_names == ref_subset.var_names).all():\n",
    "            adata_subset.var = ref_subset.var.copy()\n",
    "        \n",
    "        # Normalize separately to ensure even, comparable distributions\n",
    "        adata_subset.X = adata_subset.layers['counts']\n",
    "        sc.pp.normalize_total(adata_subset)\n",
    "        sc.pp.log1p(adata_subset)\n",
    "\n",
    "\n",
    "        cnv.tl.infercnv(\n",
    "        adata_subset,\n",
    "        reference_key=\"phenotype\",\n",
    "        reference_cat=['BPH'],\n",
    "        window_size=101,\n",
    "        step=1\n",
    "        )\n",
    "\n",
    "        infercnv_dict[sample] = adata_subset\n",
    "        print('Sample ' +sample+ ' processed: '+ str(count)+'/'+str(n_samples))\n",
    "        print('')\n",
    "    count+=1\n",
    "\n",
    "save_to_pickle(infercnv_dict,'dict_with_visium_and_infercnv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    if 'BPH' not in sample:\n",
    "        dat = infercnv_dict[sample].copy()\n",
    "        dat.obs['cluster'] = dat.obs['sample_id'] + '_' + dat.obs['joint_leiden_clusters']\n",
    "\n",
    "        # Replace entries with 'ref' if the entry string contains 'BPH', else keep the entry as it was\n",
    "        dat.obs['cluster'] = ['ref' if 'BPH' in entry else entry for entry in dat.obs['cluster']]\n",
    "\n",
    "        # Subjective choice of having ther ref plotted alongside (not much to see...)\n",
    "        dat = dat[dat.obs['cluster']!='ref']\n",
    "        # Manually clipping the values as a workaround for a bug in the source code\n",
    "        # as per https://github.com/icbi-lab/infercnvpy/issues/38\n",
    "\n",
    "        dat.var['chromosome'] = dat.var['chromosome'].cat.set_categories(chr_order)\n",
    "\n",
    "        dat.obsm[\"X_cnv\"].data = np.clip(dat.obsm[\"X_cnv\"].data, -0.3, 0.3)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 8), dpi=120)\n",
    "\n",
    "        cnv.pl.chromosome_heatmap(dat,groupby=\"cluster\", figsize=(12,8),\n",
    "        show=False)\n",
    "\n",
    "        plt.savefig('./plots/infercnv_maps_20230808/'+sample+'_infercnv_map.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and formatting inferCNV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_slides  = load_from_pickle('./data/slides_with_cell_mapping_based_regions.pkl')\n",
    "infercnv_dict = load_from_pickle('dict_with_visium_and_infercnv.pkl')\n",
    "samples = get_sample_ids_reorder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n",
      "... storing 'sample_id' as categorical\n",
      "... storing 'joint_leiden_clusters' as categorical\n",
      "... storing 'cnv_ref' as categorical\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in samples[4:]:\n",
    "    \n",
    "    icnv_sample = infercnv_dict[sample].copy()\n",
    "    slide = adata_slides[sample]\n",
    "\n",
    "    # Take out the baseline category of BPHs\n",
    "    icnv_sample = icnv_sample[slide.obs_names]\n",
    "\n",
    "    icnv_sample.obs['predicted_region'] = icnv_sample.obs['predicted_region'].astype('category').cat.set_categories(slide.obs['predicted_region'].cat.categories)\n",
    "\n",
    "    # Add the predicted region colors\n",
    "    icnv_sample.uns['predicted_region_colors'] = slide.uns['predicted_region_colors']\n",
    "\n",
    "    #cnv.pl.chromosome_heatmap_summary(icnv_sample,groupby=\"predicted_region\", figsize=(12,8),show=False)\n",
    "    cnv.pl.chromosome_heatmap(icnv_sample,groupby=\"predicted_region\", figsize=(12,8),show=False)\n",
    "    #plt.tight_layout()\n",
    "    #plt.title(sample)\n",
    "    \n",
    "    plt.savefig('./plots/infercnv_maps_20231125/'+sample+ '_icnvs_by_regions.pdf')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds of all infercnv values\n",
    "\n",
    "for lim in [0.01, 0.02, 0.05, 0.1]:\n",
    "\n",
    "    thr_low = np.quantile(infercnv_results_ravel,0+lim)\n",
    "    thr_hi = np.quantile(infercnv_results_ravel,1-lim)\n",
    "\n",
    "    print('limit: ' + str(lim))\n",
    "    print('Upper: {:.3f}, Lower: {:.3f}'.format(thr_hi,thr_low))\n",
    "    print(' ')\n",
    "\n",
    "    dat = infercnv_dict['PC_02_05601_OIK'].copy()\n",
    "\n",
    "    x_cnv = dat.obsm['X_cnv'].copy().todense()\n",
    "    x_cnv_thr = threshold_matrix(x_cnv,thr_low,thr_hi)\n",
    "\n",
    "    dat.obsm['X_cnv'] = x_cnv_thr\n",
    "\n",
    "\n",
    "    dat.obs['cluster'] = dat.obs['sample_id'] + '_' + dat.obs['joint_leiden_clusters']\n",
    "\n",
    "    # Replace entries with 'ref' if the entry string contains 'BPH', else keep the entry as it was\n",
    "    dat.obs['cluster'] = ['ref' if 'BPH' in entry else entry for entry in dat.obs['cluster']]\n",
    "\n",
    "    # Subjective choice of having ther ref plotted alongside (not much to see...)\n",
    "    dat = dat[dat.obs['cluster']!='ref']\n",
    "    # Manually clipping the values as a workaround for a bug in the source code\n",
    "    # as per https://github.com/icbi-lab/infercnvpy/issues/38\n",
    "\n",
    "    cnv.pl.chromosome_heatmap(dat,groupby=\"cluster\", figsize=(12,8),show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging across chromosomal positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_dict = {}\n",
    "for ci in [0.01,0.02,0.05,0.1,0.2,0.25]:\n",
    "    CI_dict[ci] = np.quantile(infercnv_results_ravel,ci)\n",
    "    CI_dict[1-ci] = np.quantile(infercnv_results_ravel,1-ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_thr = 0.01\n",
    "upper_limit = CI_dict[signif_thr]\n",
    "lower_limit = CI_dict[1-signif_thr]\n",
    "\n",
    "signif_thr2 = 0.1\n",
    "second_upper = CI_dict[signif_thr2]\n",
    "second_lower = CI_dict[1-signif_thr2]\n",
    "\n",
    "\n",
    "xmin = -0.25\n",
    "xmax = 0.25\n",
    "\n",
    "plt.figure(figsize=(5,4),dpi=120)\n",
    "plt.hist(infercnv_results_ravel,bins=np.arange(xmin,xmax,0.025))\n",
    "plt.xlim(xmin, xmax)\n",
    "\n",
    "# Draw 0.75 confidence intervals\n",
    "plt.axvline(x=second_upper, color='red', linestyle='dashed')\n",
    "plt.axvline(x=second_lower, color='red', linestyle='dashed')\n",
    "\n",
    "plt.axvline(x=lower_limit, color='black', linestyle='dashed')\n",
    "plt.axvline(x=upper_limit, color='black', linestyle='dashed')\n",
    "\n",
    "print('Lower significance threshold: {:.3f}'.format(lower_limit))\n",
    "print('Upper significance threshold: {:.3f}'.format(upper_limit))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5e6\n",
    "signif_thr = 0.01\n",
    "signif_thr2 = 0.1\n",
    "\n",
    "averaged_cnv_data_dict = {}\n",
    "\n",
    "#for sample in infercnv_dict.keys():\n",
    "sample = 'PC_02_10136_VAS'\n",
    "\n",
    "dat = infercnv_dict[sample].copy()\n",
    "dat.obs['cluster'] = dat.obs['sample_id'] + '_' + dat.obs['joint_leiden_clusters']\n",
    "\n",
    "# Replace entries with 'ref' if the entry string contains 'BPH', else keep the entry as it was\n",
    "dat.obs['cluster'] = ['ref' if 'BPH' in entry else entry for entry in dat.obs['cluster']]\n",
    "\n",
    "# Subjective choice of having ther ref plotted alongside (not much to see...)\n",
    "dat = dat[dat.obs['cluster']!='ref']\n",
    "\n",
    "cnv_dat = ad.AnnData(X=dat.obsm['X_cnv'].copy().todense(),obs=dat.obs.copy(),var=dat.var.copy())\n",
    "\n",
    "cnv_dat = cnv_dat[:,sort_chromosomes(cnv_dat.var).index]\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "# Bin the genes (5M base bins by default)\n",
    "\n",
    "annotated_chr_var = add_chromosome_bin_annotation(cnv_dat.var.copy(),chromosome_bin_size=window_size)\n",
    "\n",
    "cnv_dat = cnv_dat[:,annotated_chr_var.index] # THIS IS THE PLACE WHERE THE ORDER IS MIXED\n",
    "\n",
    "\n",
    "#if (annotated_chr_var.index == cnv_dat.var.index).all():\n",
    "#    cnv_dat.var = annotated_chr_var.copy()\n",
    "cnv_dat.var = pd.merge(cnv_dat.var,annotated_chr_var['chromosome_bin'],right_index=True, left_index=True,how='left').copy()\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Summarize data by variables\n",
    "\n",
    "X = cnv_dat.X.copy()\n",
    "var_data = cnv_dat.var.copy().reset_index(drop=True)\n",
    "\n",
    "sum_categories = var_data['chromosome_bin'].unique()\n",
    "\n",
    "N_obs = X.shape[0]\n",
    "N_var = len(sum_categories)\n",
    "X_summed = np.empty((N_obs, N_var))\n",
    "\n",
    "for i,chr_bin in enumerate(sum_categories):\n",
    "\n",
    "    idxs = var_data[var_data['chromosome_bin'] == chr_bin].index\n",
    "    X_summed[:,i] = X[:,idxs].mean(axis=1)\n",
    "\n",
    "# Create a new anndata object with summarized data\n",
    "cnv_data_summarized = ad.AnnData(X=X_summed,obs=cnv_dat.obs.copy(),var = pd.DataFrame(index=pd.CategoricalIndex(sum_categories).set_categories(sum_categories)))\n",
    "\n",
    "# Threshold, sort and plot\n",
    "cnv_data_summarized.X = threshold_matrix(cnv_data_summarized.X,CI_dict[signif_thr],CI_dict[1-signif_thr],CI_dict[signif_thr2],CI_dict[1-signif_thr2]) # This are the 0.02 and 0.98 quantiles\n",
    "#cnv_data_summarized = cnv_data_summarized[:,sum_categories] # Sort the cnv data\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Add chromosome breakpoints into the data\n",
    "\n",
    "chr_pos_dict = {}\n",
    "var_group_positions = []\n",
    "for i,c in enumerate(list(chr_order)):\n",
    "    \n",
    "    idxs = np.where([c+'.' in idx for idx in cnv_data_summarized.var.index])[0]\n",
    "    chr_pos_dict[c] = idxs[0]\n",
    "    var_group_positions.append((idxs[0],idxs[-1]))\n",
    "\n",
    "chr_pos = list(chr_pos_dict.values())\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "return_ax_dic = sc.pl.heatmap(cnv_data_summarized,var_names=cnv_data_summarized.var_names,groupby='cluster',cmap='bwr',\n",
    "                                vcenter=0, vmin = -2, vmax = 2, figsize=(12,6), show=False,\n",
    "            var_group_positions=var_group_positions, var_group_labels=list(chr_pos_dict.keys()))\n",
    "return_ax_dic['heatmap_ax'].vlines(chr_pos[1:], lw=0.6, ymin=-1, ymax=len(cnv_data_summarized))\n",
    "\n",
    "averaged_cnv_data_dict[sample] = cnv_data_summarized\n",
    "\n",
    "#plt.savefig('./plots/infercnv_maps_20230808/'+sample+'_{:.0e}_binned_events_infercnv_map.pdf'.format(window_size))\n",
    "#plt.clf()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data for annotation\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "dat = infercnv_dict['PC_02_05601_OIK'].copy()\n",
    "dat.var.to_csv('icnv_annotation/gene_annotations.csv')\n",
    "dat.obs.to_csv('icnv_annotation/obs_annotations.csv')\n",
    "save_npz('icnv_annotation/icnv_data.npz',dat.obsm['X_cnv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
